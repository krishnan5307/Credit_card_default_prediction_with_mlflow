grid_search:
  class: GridSearchCV
  module: sklearn.model_selection
  params:
    cv: 5
    verbose: 2

model_selection:
  module_0:
    class: LogisticRegression
    module: sklearn.linear_model
    params:
      C: 1.0
      solver: 'lbfgs'
    search_param_grid:
      C:
        - 0.1
        - 1.0
        - 10.0
      solver:
        - 'lbfgs'
        - 'liblinear'

  module_1:
    class: RandomForestClassifier
    module: sklearn.ensemble
    params:
      n_estimators: 100
      min_samples_leaf: 1
    search_param_grid:
      n_estimators:
        - 50
        - 100

      min_samples_leaf:
        - 1
        - 3
        

  module_2:
    class: GradientBoostingClassifier
    module: sklearn.ensemble
    params:
      n_estimators: 100
      learning_rate: 0.1
    search_param_grid:
      n_estimators:
        - 50
        - 100
        
      learning_rate:
        - 0.05
        - 0.1
        

  module_3:
    class: AdaBoostClassifier
    module: sklearn.ensemble
    params:
      n_estimators: 50
      learning_rate: 1.0
    search_param_grid:
      n_estimators:
        - 50
        - 100

      learning_rate:
        - 0.5
        - 1.0
  
  module_4:
    class: BernoulliNB
    module: sklearn.naive_bayes
    params:
      alpha: 1.0
      binarize: 0.0
    search_param_grid:
      alpha:
        - 0.1
        - 1.0
        - 10.0
      binarize:
        - 0.0
        - 0.5
        - 1.0





 ## These models below are not used as they dont have a predict_proba() function to return probability of classes. eg: percentages/fraction in btw 0 and 1
 ## they only have predict() function that returns target classes in which user data belongs . eg: 0 or 1 here    
  
  # module_5:      ## SVC has predict_proba() function but it requires 5x computation and we need to set param SVC(probility =True) before training 
  #   class: SVC
  #   module: sklearn.svm
  #   params:
  #     C: 1.0
  #     kernel: 'rbf'
  #   search_param_grid:
  #     C:
  #       - 0.1
  #       - 0.5
       
  #     kernel:
  #       - 'rbf'
  #       - 'linear'
  #       - 'sigmoid'

  # module_6:
  #   class: DecisionTreeClassifier
  #   module: sklearn.tree
  #   params:
  #     criterion: 'gini'
  #     min_samples_leaf: 1
  #   search_param_grid:
  #     criterion:
  #       - 'gini'
  #       - 'entropy'
  #     min_samples_leaf:
  #       - 1
  #       - 3
       
 

# """
# Bernoulli Naive Bayes (BernoulliNB):
# Suitability:

# Typically used for binary or binarized data (0s and 1s).
# Suitable for features that follow a Bernoulli distribution.
# Assumptions:

# Assumes that features are binary-valued (e.g., presence or absence of a feature).
# Often used in text classification, where features represent the presence or absence of words in a document.
# Hyperparameters:

# alpha: Smoothing parameter for handling zero probabilities.

# """




# """
# Multinomial Naive Bayes (MultinomialNB):
# Suitability:

# Commonly used for text classification tasks with discrete data (e.g., word counts or term frequency).
# Suitable for features that represent counts or frequencies.
# Assumptions:

# Assumes that features are counts or frequencies (non-negative integers).
# Hyperparameters:

# alpha: Smoothing parameter for handling zero probabilities.
# """

  # module_7:
  #   class: MultinomialNB
  #   module: sklearn.naive_bayes
  #   params:
  #     alpha: 1.0
  #   search_param_grid:
  #     alpha:
  #       - 0.1
  #       - 1.0
  #       - 10.0


















# grid_search:
#   class: GridSearchCV
#   module: sklearn.model_selection
#   params:
#     cv: 5
#     verbose: 2
# model_selection:
#   module_0:
#     class: LinearRegression
#     module: sklearn.linear_model
#     params:
#       fit_intercept: true
#     search_param_grid:
#       fit_intercept:
#       - true
#       - false
#   module_1:
#     class: RandomForestRegressor
#     module: sklearn.ensemble
#     params:
#       min_samples_leaf: 3
#     search_param_grid:
#       min_samples_leaf:
#       - 6
#   module_2: 
#     class: GradientBoostingRegressor  
#     module: sklearn.ensemble
#     params:
#       n_estimators: 100
#       criterion: friedman_mse
#     search_param_grid:
#       n_estimators:
#       - 120
#       - 70
#       - 30
#       criterion:
#       - friedman_mse
#       - squared_error
#   module_3: 
#     class: DecisionTreeRegressor  
#     module: sklearn.tree
#     params:
#       criterion: squared_error
#       min_samples_leaf: 3 
#     search_param_grid:
#       criterion:
#       - squared_error
#       - absolute_error
#       min_samples_leaf:
#       - 6 
#   module_4: 
#     class: SVR  
#     module: sklearn.svm
#     params:
#       kernel: rbf
#       gamma: scale
#       min_samples_leaf: 3 
#     search_param_grid:
#       kernel:
#       - rbf
#       - linear
#       - sigmoid
#       gamma:
#       - auto
#   module_5: 
#     class: AdaBoostRegressor  
#     module: sklearn.ensemble
#     params:
#       n_estimators: 50
#       loss: linear
#     search_param_grid:
#       n_estimators:
#       - 100
#       - 70
#       - 30
#       loss:
#       - linear
#       - square
#       - exponential
  